const generatedBibEntries = {
    "Lewis2020RAG": {
        "abstract": "This paper introduces RAG, a model combining retrieval and generation to enhance knowledge-intensive NLP tasks.",
        "author": "Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; et al.",
        "doi": "10.48550/arXiv.2005.11401",
        "journal": "Advances in Neural Information Processing Systems",
        "keywords": "Core Methods, RAG, NLP",
        "number": "",
        "publisher": "NeurIPS",
        "series": "NeurIPS",
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
        "type": "article",
        "url": "https://arxiv.org/abs/2005.11401",
        "volume": "33",
        "year": "2020"
    },
    "Izacard2021FiD": {
        "abstract": "The authors present FiD, a framework that processes retrieved passages jointly within the decoder to improve QA performance.",
        "author": "Izacard, Gautier; Grave, Edouard",
        "doi": "10.48550/arXiv.2007.01282",
        "journal": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics",
        "keywords": "Core Methods, FiD, QA",
        "number": "",
        "publisher": "EACL",
        "series": "EACL",
        "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
        "type": "article",
        "url": "https://arxiv.org/abs/2007.01282",
        "volume": "",
        "year": "2021"
    },
    "Zhu2021Survey": {
        "abstract": "This survey reviews developments in open-domain QA, highlighting the shift toward integrated retrieval-generation systems.",
        "author": "Zhu, Yichong; Tang, Shumin; Liu, Yixin; He, Jiazhan; Li, Juncheng",
        "doi": "10.48550/arXiv.2101.00774",
        "journal": "ACM Computing Surveys",
        "keywords": "Survey, Open-Domain QA, RAG",
        "number": "",
        "publisher": "ACM",
        "series": "ACM Computing Surveys",
        "title": "A Survey on Open-Domain Question Answering",
        "type": "article",
        "url": "https://arxiv.org/abs/2101.00774",
        "volume": "",
        "year": "2021"
    },
    "Devlin2019BERT": {
        "abstract": "BERT introduced deep bidirectional transformers, which have become a foundation for modern NLP models including RAG.",
        "author": "Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina",
        "doi": "10.48550/arXiv.1810.04805",
        "journal": "Proceedings of NAACL-HLT",
        "keywords": "Background, NLP, Transformer",
        "number": "",
        "publisher": "NAACL",
        "series": "NAACL",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "type": "article",
        "url": "https://arxiv.org/abs/1810.04805",
        "volume": "",
        "year": "2019"
    },
    "Asai2020MultihopQA": {
        "abstract": "This paper explores multihop QA, where answers require reasoning across multiple retrieved documents.",
        "author": "Asai, Akari; Hajishirzi, Hannaneh",
        "doi": "10.48550/arXiv.2004.07446",
        "journal": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
        "keywords": "Applications, Multihop QA, Reasoning",
        "number": "",
        "publisher": "EMNLP",
        "series": "EMNLP",
        "title": "Multihop Question Answering with Cross-Document Reasoning",
        "type": "article",
        "url": "https://arxiv.org/abs/2004.07446",
        "volume": "",
        "year": "2020"
    },
    "OpenAI2023GPT4": {
        "abstract": "The GPT-4 report describes advances in large language models, which are often paired with retrieval modules in RAG frameworks.",
        "author": "OpenAI",
        "doi": "10.48550/arXiv.2303.08774",
        "journal": "arXiv",
        "keywords": "Background, GPT-4, LLM",
        "number": "",
        "publisher": "OpenAI",
        "series": "arXiv",
        "title": "GPT-4 Technical Report",
        "type": "article",
        "url": "https://arxiv.org/abs/2303.08774",
        "volume": "",
        "year": "2023"
    },
    "Liu2023ChatGPTQA": {
        "abstract": "This study examines ChatGPT’s potential as a knowledge-based QA system and discusses its limitations and strengths.",
        "author": "Liu, Jing; Zhao, Wei; Lin, Jimmy; McKeown, Kathleen",
        "doi": "10.48550/arXiv.2302.06476",
        "journal": "arXiv",
        "keywords": "Applications, ChatGPT, QA",
        "number": "",
        "publisher": "arXiv",
        "series": "arXiv",
        "title": "ChatGPT as a Knowledge-Based QA System",
        "type": "article",
        "url": "https://arxiv.org/abs/2302.06476",
        "volume": "",
        "year": "2023"
    },
    "Yu2022RAGSurvey": {
        "abstract": "This paper provides a broad review of Retrieval-Augmented Generation systems, covering architectures and use cases.",
        "author": "Yu, Xiaoyang; Wang, Lei; Zhang, Han; et al.",
        "doi": "10.48550/arXiv.2206.06488",
        "journal": "arXiv",
        "keywords": "Survey, RAG, NLP",
        "number": "",
        "publisher": "arXiv",
        "series": "arXiv",
        "title": "A Comprehensive Survey of RAG Systems",
        "type": "article",
        "url": "https://arxiv.org/abs/2206.06488",
        "volume": "",
        "year": "2022"
    },
    "Thakur2021BEIR": {
        "abstract": "BEIR provides a benchmark for evaluating retrieval models across multiple datasets, widely used in assessing RAG retrieval components.",
        "author": "Thakur, Nandan; Reimers, Nils; Reddy, Abhishek; et al.",
        "doi": "10.48550/arXiv.2104.08663",
        "journal": "arXiv",
        "keywords": "Evaluation Tools, BEIR, Benchmark",
        "number": "",
        "publisher": "arXiv",
        "series": "arXiv",
        "title": "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models",
        "type": "article",
        "url": "https://arxiv.org/abs/2104.08663",
        "volume": "",
        "year": "2021"
    },
    "Zhang2023HealthcareRAG": {
        "abstract": "The authors explore how RAG frameworks can be applied in healthcare, improving medical question answering and decision support.",
        "author": "Zhang, Wei; Li, Jun; Wang, Xiaoyan",
        "doi": "10.48550/arXiv.2305.00001",
        "journal": "arXiv",
        "keywords": "Applications, Healthcare, RAG",
        "number": "",
        "publisher": "arXiv",
        "series": "arXiv",
        "title": "RAG in Healthcare Applications",
        "type": "article",
        "url": "https://arxiv.org/abs/2305.00001",
        "volume": "",
        "year": "2023"
    }
};
